{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hSmt_38LPsv"
      },
      "outputs": [],
      "source": [
        "mkdir -p raw_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd raw_data"
      ],
      "metadata": {
        "id": "5vVsS9sLLf8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://clinicaltrials.gov/AllPublicXML.zip"
      ],
      "metadata": {
        "id": "8O63-2ZtLlnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q AllPublicXML.zip"
      ],
      "metadata": {
        "id": "oD8ENOcmLpBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "\n",
        "def pull_tag_content(root_node, tag_path):\n",
        "    content_list = []\n",
        "    stack = [(root_node, '')]\n",
        "\n",
        "    while stack:\n",
        "        node, prefix = stack.pop()\n",
        "        path = prefix + '/' + node.tag\n",
        "\n",
        "        if path == tag_path and node.text:\n",
        "            content_list.append(node.text)\n",
        "\n",
        "        for child in node:\n",
        "            stack.append((child, path))\n",
        "\n",
        "    return content_list\n",
        "\n",
        "def extract_criteria(criteria_textblock):\n",
        "    # Find the positions of \"Inclusion Criteria:\" and \"Exclusion Criteria:\"\n",
        "    c1 = criteria_textblock.find(\"Inclusion Criteria:\",0)\n",
        "    c2 = criteria_textblock.find(\"Exclusion Criteria:\",0)\n",
        "\n",
        "    # Extract the Inclusion Criteria and handle missing criteria\n",
        "    if c1 >= 0:\n",
        "        if c2 >= 0:\n",
        "            inclusion_criteria = criteria_textblock[c1 + len(\"Inclusion Criteria:\"):c2].strip()\n",
        "        else:\n",
        "            inclusion_criteria = criteria_textblock[c1 + len(\"Inclusion Criteria:\"):].strip()\n",
        "    else:\n",
        "        inclusion_criteria = \"\"\n",
        "\n",
        "    # Extract the Exclusion Criteria and handle missing criteria\n",
        "    if c2 >= 0:\n",
        "        if c1 >= 0:\n",
        "            exclusion_criteria = criteria_textblock[c2 + len(\"Exclusion Criteria:\"):].strip()\n",
        "        else:\n",
        "            exclusion_criteria = criteria_textblock[c2 + len(\"Exclusion Criteria:\"):].strip()\n",
        "    else:\n",
        "        exclusion_criteria = \"\"\n",
        "    return inclusion_criteria, exclusion_criteria\n",
        "\n",
        "def read_xml_file(file_path):\n",
        "    try:\n",
        "        # Parse the XML file\n",
        "        tree = ET.parse(file_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        clinical_data = {\n",
        "            'nct_id': root.findtext('id_info/nct_id',''),\n",
        "            'brief_title': root.findtext('brief_title',''),\n",
        "            'official_title': root.findtext('official_title',''),\n",
        "            'agency': root.findtext('sponsors/lead_sponsor/agency',''),\n",
        "            'agency_class': root.findtext('sponsors/lead_sponsor/agency_class',''),\n",
        "            'collaborator_agency': root.findtext('sponsors/collaborator/agency',''),\n",
        "            'brief_summary': root.findtext('brief_summary/textblock',''),\n",
        "            'detailed_description': root.findtext('detailed_description/textblock',''),\n",
        "            # 'conditions': root.findtext('condition',''),\n",
        "            'overall_status': root.findtext('overall_status',''),\n",
        "            'phase': root.findtext('phase',''),\n",
        "            'study_type': root.findtext('study_type',''),\n",
        "            'has_expanded_access': root.findtext('has_expanded_access',''),\n",
        "            'intervention': root.findtext('intervention',''),\n",
        "            'intervention_type': root.findtext('intervention/intervention_type',''),\n",
        "            'intervention_name': root.findtext('intervention/intervention_name',''),\n",
        "            'lead_sponsor_agency': root.find('sponsors/lead_sponsor/agency',''),\n",
        "            'primary_completion_date': root.findtext('primary_completion_date',''),\n",
        "            'start_date': root.findtext('start_date',''),\n",
        "            'completion_date': root.findtext('completion_date',''),\n",
        "            'gender': root.findtext('eligibility/gender',''),\n",
        "            'minimum_age': root.findtext('eligibility/minimum_age',''),\n",
        "            'maximum_age': root.findtext('eligibility/maximum_age',''),\n",
        "            'healthy_volunteers': root.findtext('eligibility/healthy_volunteers',''),\n",
        "            'why_stopped': root.findtext('why_stopped',''),\n",
        "        }\n",
        "        # check for multipal marks\n",
        "        conditions = pull_tag_content(root, '/clinical_study/condition')\n",
        "        keywords = pull_tag_content(root, '/clinical_study/keyword')\n",
        "        clinical_data['conditions'] = conditions\n",
        "        clinical_data['keywords'] = keywords\n",
        "        # Extract Inclusion and Exclusion Criteria\n",
        "        criteria_textblock = root.findtext('eligibility/criteria/textblock','')\n",
        "        inclusion_criteria, exclusion_criteria = extract_criteria(criteria_textblock)\n",
        "        clinical_data['inclusion_criteria'] = inclusion_criteria\n",
        "        clinical_data['exclusion_criteria'] = exclusion_criteria\n",
        "        return clinical_data\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{file_path}' not found.\")\n",
        "        return None\n",
        "    except ET.ParseError:\n",
        "        print(f\"Error: Invalid XML format in '{file_path}'.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def save_to_csv(data_list, csv_file):\n",
        "    with open(csv_file, 'w', newline='', encoding='utf-8') as f:\n",
        "        fieldnames = data_list[0].keys()\n",
        "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        writer.writerows(data_list)"
      ],
      "metadata": {
        "id": "Qg1PwWpQNBVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data_dir = '/content/raw_data'\n",
        "import os\n",
        "# # Create an empty list to store all the file paths\n",
        "all_file_paths = []\n",
        "\n",
        "# # Use os.walk to traverse through all subdirectories in 'raw_data'\n",
        "for dirpath, _, filenames in os.walk(raw_data_dir):\n",
        "    # Concatenate the directory path with the filenames to get the full file paths\n",
        "    file_paths = [os.path.join(dirpath, filename) for filename in filenames]\n",
        "    # Extend the all_file_paths list with the file_paths list for each subdirectory\n",
        "    all_file_paths.extend(file_paths)\n"
      ],
      "metadata": {
        "id": "8W-XXxnmNVPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_list = []\n",
        "# for file_path in all_file_paths:\n",
        "#     if file_path.endswith(\".xml\"):\n",
        "#         clinical_data = read_xml_file(file_path)\n",
        "#         if clinical_data is not None:\n",
        "#             data_list.append(clinical_data)\n",
        "\n",
        "csv_file= '/content/data_output/combine_output.csv'\n",
        "if data_list:\n",
        "        save_to_csv(data_list, csv_file)\n",
        "        print(f\"Data from {len(data_list)} XML files saved to '{csv_file}' successfully.\")\n",
        "else:\n",
        "    print(\"No valid data found in XML files.\")"
      ],
      "metadata": {
        "id": "En3a1bmeNvGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mzDE-QCC1e0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/drive/MyDrive/Mtech /Dissertation/data_output/combine_output.csv')\n",
        "df.head(2)\n",
        "# for i in df.columns:\n",
        "#   print(i,df[i].tolist(),end='\\n')"
      ],
      "metadata": {
        "id": "KhsVBIUvNxj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "4YAWEPEeQVQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have loaded your data into a pandas DataFrame called 'df'\n",
        "# If not, load your data into 'df' using pandas read_csv or any other method.\n",
        "\n",
        "# Create the null value DataFrame (True for null, False for non-null)\n",
        "null_df = df.isnull()\n",
        "\n",
        "# Set a custom color palette for the heatmap (diverging color map with blue and yellow)\n",
        "colors = ['#4374B3', '#F9D574']\n",
        "\n",
        "# Create the heatmap using seaborn\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(null_df, cmap=sns.color_palette(colors), cbar=False, yticklabels=False)\n",
        "\n",
        "# Add a title and labels to the heatmap\n",
        "plt.title('Null Values Heatmap', fontsize=20)\n",
        "plt.xlabel('Columns', fontsize=14)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nMBHLVOOaF6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Data Visualization\n",
        "# Histograms for Numerical Columns\n",
        "numerical_cols = ['phase']#, 'minimum_age', 'maximum_age']\n",
        "for col in numerical_cols:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.histplot(df[col].dropna(), kde=True, color='blue', bins=30)\n",
        "    plt.title(f'Histogram of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1_nwcWMKn08I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = ['agency_class', 'gender', 'healthy_volunteers']\n",
        "\n",
        "num_plots = len(categorical_cols)\n",
        "num_rows = num_plots\n",
        "num_cols = 1\n",
        "\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(8, 6*num_rows))\n",
        "\n",
        "# Plot settings\n",
        "sns.set_palette(\"viridis\")\n",
        "\n",
        "for i, col in enumerate(categorical_cols):\n",
        "    sns.countplot(data=df, x=col, palette='viridis', ax=axes[i])\n",
        "    axes[i].set_title(f'Count of {col}')\n",
        "    axes[i].set_xlabel(col)\n",
        "    axes[i].set_ylabel('Count')\n",
        "    axes[i].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.subplots_adjust(hspace=0.5)  # Adjust the vertical spacing between subplots\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O5vPISs13SxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = ['overall_status', 'study_type']\n",
        "\n",
        "num_plots = len(categorical_cols)\n",
        "num_rows = 1\n",
        "num_cols = num_plots\n",
        "\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(12,6))\n",
        "\n",
        "# Plot settings\n",
        "sns.set_palette(\"viridis\")\n",
        "\n",
        "for i, col in enumerate(categorical_cols):\n",
        "    sns.countplot(data=df, x=col, palette='viridis', ax=axes[i])\n",
        "    axes[i].set_title(f'Count of {col}')\n",
        "    axes[i].set_xlabel(col)\n",
        "    axes[i].set_ylabel('Count')\n",
        "    axes[i].tick_params(axis='x', rotation=90)\n",
        "\n",
        "plt.tight_layout()  # Automatically adjust spacing between subplots\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kGNIVzrr5RXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(data=df[df['why_stopped'].notnull()], x='phase', palette='viridis')\n",
        "plt.title('Count of Why Stopped Across Phases')\n",
        "plt.xlabel('Phase')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JX_oTiHj7PHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Data Analysis (if relevant, for text columns)\n",
        "# Example: Word Cloud for 'brief_summary'\n",
        "# from wordcloud import WordCloud\n",
        "\n",
        "# text_column = 'why_stopped'\n",
        "# text_data = \" \".join(text for text in df[text_column].dropna())\n",
        "# wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text_data)\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.imshow(wordcloud, interpolation='bilinear')\n",
        "# plt.title(f'Word Cloud for {text_column}')\n",
        "# plt.axis('off')\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "K5DBm9_MaiR6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}