{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "mkdir -p raw_data\n",
        "cd raw_data\n",
        "!wget -q https://clinicaltrials.gov/AllPublicXML.zip\n",
        "\n",
        "!unzip -q AllPublicXML.zip\n",
        "raw_data_dir = '/content/raw_data'\n",
        "import os\n",
        "# # Create an empty list to store all the file paths\n",
        "all_file_paths = []\n",
        "\n",
        "# # Use os.walk to traverse through all subdirectories in 'raw_data'\n",
        "for dirpath, _, filenames in os.walk(raw_data_dir):\n",
        "    # Concatenate the directory path with the filenames to get the full file paths\n",
        "    file_paths = [os.path.join(dirpath, filename) for filename in filenames]\n",
        "    # Extend the all_file_paths list with the file_paths list for each subdirectory\n",
        "    all_file_paths.extend(file_paths)"
      ],
      "metadata": {
        "id": "KijEdb-MOPW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_file_paths"
      ],
      "metadata": {
        "id": "jDKPuOFNbFJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file=[]\n",
        "for i in all_file_paths:\n",
        "  if 'xml' in i:\n",
        "    file.append(i)"
      ],
      "metadata": {
        "id": "5RAQGUiTOQc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjimxBZGrI8S",
        "outputId": "1f00dbdf-2944-46fb-9e7f-ec5bcf12fa14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/raw_data/NCT0317xxxx/NCT03178747.xml',\n",
              " '/content/raw_data/NCT0317xxxx/NCT03171714.xml']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, csv, pickle\n",
        "from xml.dom import minidom\n",
        "from xml.etree import ElementTree as ET\n",
        "from collections import defaultdict\n",
        "from time import time\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "\n",
        "\n",
        "\n",
        "### tricky\n",
        "def normalize_disease(name):\n",
        "    name = name.lower()\n",
        "    if 'lymphoma' in name:\n",
        "      return 'lymphoma'\n",
        "    name = name.replace(',', '')\n",
        "    name = name.replace('(', ' ')\n",
        "    name = name.replace(')', ' ')\n",
        "\n",
        "    name = name.replace('cancer', 'neoplasm')\n",
        "    name = name.replace('neoplasms', 'neoplasm')\n",
        "    name = name.replace('tumors', 'tumor')\n",
        "\n",
        "    name = name.replace('infections', 'infection')\n",
        "    name = name.replace('diseases', 'disease')\n",
        "    name = name.replace('disorders', 'disorder')\n",
        "    name = name.replace('syndromes', 'syndrome')\n",
        "\n",
        "    name = ' '.join(name.split())\n",
        "    if name.split()[0]=='stage':\n",
        "      name = ' '.join(name.split()[2:])\n",
        "\n",
        "    name_lst = [name]\n",
        "    if ' neoplasm' in name:\n",
        "      # print(name)\n",
        "      name_lst.append(name.replace('neoplasm', 'tumor'))\n",
        "      name_split = name.split()\n",
        "      idx = name_split.index('neoplasm')\n",
        "      name2 = name_split[idx-1] + ' ' + name_split[idx]\n",
        "      name_lst.append(name2)\n",
        "    if ' tumor' in name:\n",
        "      name_lst.append(name.replace('tumor', 'neoplasm'))\n",
        "      name_split = name.split()\n",
        "      idx = name_split.index('tumor')\n",
        "      name2 = name_split[idx-1] + ' ' + name_split[idx]\n",
        "      name_lst.append(name2)\n",
        "    if 'disease' in name:\n",
        "      name_lst.append(name.replace('disease', '').strip())\n",
        "    if 'disorder' in name:\n",
        "      name_lst.append(name.replace('disorder', '').strip())\n",
        "    if '-related' in name:\n",
        "      name_lst.append(name.replace('-related', '').strip())\n",
        "    if 'syndrome' in name:\n",
        "      name_lst.append(name.replace('syndrome', '').strip())\n",
        "\n",
        "\n",
        "    if 'lung' in name and 'carcinoma' in name:\n",
        "      name_lst.append('lung carcinoma')\n",
        "    elif 'cell' in name and 'carcinoma' in name:\n",
        "      name_lst.append('cell carcinoma')\n",
        "    elif 'carcinoma' in name:\n",
        "      name_lst.append('carcinoma')\n",
        "\n",
        "\n",
        "\n",
        "    ## approximation 1\tvery few\n",
        "    organ = ['liver', 'kidney', 'cardio', 'renal', 'hiv']\n",
        "    for word in organ:\n",
        "      if word in name:\n",
        "        name_lst.append(word)\n",
        "\n",
        "    # approximation 2 most 20%\n",
        "    word_lst = sorted([(word, len(word)) for word in name.split()], key = lambda x:x[1], reverse = True)\n",
        "    for word, cnt in word_lst:\n",
        "      if cnt < 8:\n",
        "        break\n",
        "      name_lst.append(word)\n",
        "\n",
        "    return name_lst\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_icd_from_nih(name):\n",
        "    prefix = 'https://clinicaltables.nlm.nih.gov/api/icd10cm/v3/search?sf=code,name&terms='\n",
        "    name_lst = normalize_disease(name)\n",
        "    for name in name_lst:\n",
        "        url = prefix + name\n",
        "        response = requests.get(url)\n",
        "        text = response.text\n",
        "        if text == '[0,[],null,[]]':\n",
        "          continue\n",
        "        text = text[1:-1]\n",
        "        idx1 = text.find('[')\n",
        "        idx2 = text.find(']')\n",
        "        codes = text[idx1+1:idx2].split(',')\n",
        "        codes = [i[1:-1] for i in codes]\n",
        "        return codes\n",
        "    return None\n",
        "\n",
        "def walkData(root_node, prefix, result_list):\n",
        "\n",
        "    temp_list = [prefix + '/' + root_node.tag, root_node.text]\n",
        "    result_list.append(temp_list)\n",
        "\n",
        "    for child in root_node:\n",
        "        walkData(child, prefix=prefix + '/' + root_node.tag, result_list=result_list)\n",
        "\n",
        "\n",
        "def root2outcome(root):\n",
        "    result_list = []\n",
        "    walkData(root, prefix = '', result_list = result_list)\n",
        "    filter_func = lambda x:'p_value' in x[0]\n",
        "    outcome_list = list(filter(filter_func, result_list))\n",
        "    if len(outcome_list)==0:\n",
        "      return None\n",
        "    outcome = outcome_list[0][1]\n",
        "    if outcome[0]=='<':\n",
        "      return 1\n",
        "    if outcome[0]=='>':\n",
        "      return 0\n",
        "    if outcome[0]=='=':\n",
        "      outcome = outcome[1:]\n",
        "    try:\n",
        "      label = float(outcome)\n",
        "      if label < 0.05:\n",
        "        return 1\n",
        "      else:\n",
        "        return 0\n",
        "    except:\n",
        "      return None\n",
        "\n",
        "\n",
        "def xml_file_2_tuple(xml_file):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    nctid = root.find('id_info').find('nct_id').text\t### nctid: 'NCT00000102'\n",
        "    study_type = root.find('study_type').text\n",
        "    if study_type != 'Interventional':\n",
        "      return (None,)  ### invalid\n",
        "\n",
        "    interventions = [i for i in root.findall('intervention')]\n",
        "    drug_interventions = [i.find('intervention_name').text for i in interventions \\\n",
        "                              if i.find('intervention_type').text=='Drug']\n",
        "                              # or i.find('intervention_type').text=='Biological']\n",
        "    if len(drug_interventions)==0:\n",
        "      return (None,)\n",
        "\n",
        "    try:\n",
        "      status = root.find('overall_status').text\n",
        "    except:\n",
        "      status = ''\n",
        "    # if status in drop_set:\n",
        "    # \treturn (None,)  ### invalid\n",
        "    try:\n",
        "      why_stop = root.find('why_stopped').text\n",
        "    except:\n",
        "      why_stop = ''\n",
        "    label = root2outcome(root)\n",
        "    label = -1 if label is None else label\n",
        "\n",
        "\n",
        "    conditions = [i.text for i in root.findall('condition')]\n",
        "    conditions = [i.lower() for i in conditions]\n",
        "    return conditions, label, why_stop, None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def process_all():\n",
        "    output_file = '/content/output/diseases.csv'\n",
        "    t1 = time()\n",
        "    disease_hit, disease_all = 0,0 ### disease hit icd && drug hit smiles\n",
        "    input_file_lst = file\n",
        "    disease2icd_and_cnt = dict()\n",
        "    unfounded_disease_cnt = defaultdict(int)\n",
        "    word_cnt = defaultdict(int)\n",
        "    fieldname = ['disease', 'icd', 'count']\n",
        "\n",
        "    data_count = 0\n",
        "    for name in tqdm(input_file_lst[:]):\n",
        "        result = xml_file_2_tuple(name)\n",
        "        ## 0.1 & 0.2\n",
        "        if len(result)==1:\n",
        "            continue \t### only interventions\n",
        "        conditions, label, why_stop, _ = result\n",
        "        ## 0.4\n",
        "        if (label == -1) and ('lack of efficacy' in why_stop or 'efficacy concern' in why_stop or \\\n",
        "        'accrual' in why_stop):\n",
        "            label = 0\n",
        "        ## 0.5\n",
        "        if label == -1:\n",
        "            continue\n",
        "        data_count += 1\n",
        "        icdcode_lst = []\n",
        "        for disease in conditions:\n",
        "            disease_all += 1\n",
        "            disease_hit += 1\n",
        "            if disease in disease2icd_and_cnt:\n",
        "                disease2icd_and_cnt[disease][1] += 1\n",
        "                if disease2icd_and_cnt[disease][0] == 'None':\n",
        "                    disease_hit -= 1\n",
        "                    unfounded_disease_cnt[disease] += 1\n",
        "            else:\n",
        "                codes = get_icd_from_nih(disease)\n",
        "                if codes is None:\n",
        "                    disease2icd_and_cnt[disease] = ['None', 1]\n",
        "                    disease_hit -= 1\n",
        "                    unfounded_disease_cnt[disease] += 1\n",
        "                else:\n",
        "                    disease2icd_and_cnt[disease] = [codes, 1]\n",
        "\n",
        "    t2 = time()\n",
        "    disease2cnt = sorted([(k,v) for k,v in unfounded_disease_cnt.items()], key = lambda x:x[1], reverse = True)\n",
        "    for disease, cnt in disease2cnt:\n",
        "        for word in disease.split():\n",
        "            word_cnt[word] += cnt\n",
        "\n",
        "    disease_icd_cnt = sorted([[disease,icd,cnt] for disease,(icd,cnt) in disease2icd_and_cnt.items()], key = lambda x:x[2], reverse=True)\n",
        "\n",
        "    ### output\n",
        "    with open(output_file, 'w') as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldname)\n",
        "        writer.writeheader()\n",
        "        for disease, icd, cnt in disease_icd_cnt:\n",
        "            writer.writerow({'disease':disease, 'icd':icd, 'count':cnt})\n",
        "\n",
        "\n",
        "    ### use for debug\n",
        "    with open('unfounded_disease_cnt.txt', 'w') as fout:\n",
        "        for disease, cnt in disease2cnt:\n",
        "            fout.write(disease + '\\t\\t' + str(cnt) + '\\n')\n",
        "        fout.write('\\n'*10)\n",
        "        word_cnt = sorted([(w,c) for w,c in word_cnt.items()], key = lambda x:x[1], reverse = True)\n",
        "        for word, cnt in word_cnt:\n",
        "            fout.write(word + '\\t\\t' + str(cnt) + '\\n')\n",
        "\n",
        "    print(\"disease hit icdcode\", disease_hit, \"disease all\", disease_all)\n",
        "    print(str(int((t2-t1)/60)) + \" minutes. \" + str(data_count) + \" data samples. \")\n",
        "    return\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KYzUR32NppSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSiPOGByFY7J",
        "outputId": "35d455b8-6894-4b30-ea88-77f71ecc55a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 460207/460207 [46:11<00:00, 166.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "disease hit icdcode 19868 disease all 21839\n",
            "46 minutes. 13713 data samples. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}